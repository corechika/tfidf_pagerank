{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file(output_file, matrix):\n",
    "    with open('./Assignment2_Files/output/'+output_file, 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        for m in matrix:\n",
    "            writer.writerow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'assg2DocSet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq_tf(words):\n",
    "    frequency = defaultdict(int)\n",
    "    for token in words:\n",
    "        frequency[token] += 1\n",
    "    return dict(frequency)\n",
    "\n",
    "def count_freq_idf(words):\n",
    "    frequency = defaultdict(int)\n",
    "    word_list = []\n",
    "    for token in words:\n",
    "        if token in word_list: continue\n",
    "        frequency[token] += 1\n",
    "        word_list.append(token)\n",
    "    return dict(frequency)\n",
    "\n",
    "# IDFの計算\n",
    "def calc_idf(n, word_freq):\n",
    "    return np.log10(n/word_freq)\n",
    "\n",
    "tfidf = []\n",
    "tf = []\n",
    "count_row = 0\n",
    "all_doc = []\n",
    "\n",
    "with open('./Assignment2_Files/'+file_name) as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # idf\n",
    "    for row in reader:\n",
    "        all_doc.extend(row)\n",
    "        count_row += 1\n",
    "    idf_freq = count_freq_idf(all_doc)\n",
    "    idf = {}\n",
    "    for key, value in idf_freq.items():\n",
    "        idf[key] = calc_idf(count_row, value)\n",
    "\n",
    "with open('./Assignment2_Files/'+file_name) as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # tf & tfidf\n",
    "    for row in reader:\n",
    "        tf = {}\n",
    "        fr = count_freq_tf(row)\n",
    "        freq_max = max(fr.values())\n",
    "        for key, freq in fr.items():\n",
    "            tf[key] = freq / freq_max\n",
    "        buff = []\n",
    "        for key in range(1, 11):\n",
    "            if str(key) not in tf.keys():\n",
    "                buff.append(0.0)\n",
    "                continue\n",
    "            buff.append(tf[str(key)]*idf[str(key)])\n",
    "        tfidf.append(buff)\n",
    "\n",
    "tfidf = np.round(tfidf, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('M17335883.csv', tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_csv('./Assignment2_Files/output/M17335883.csv', header=None)\n",
    "query = pd.read_csv('./Assignment2_Files/query_tfidf.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = doc.values\n",
    "similarity = []\n",
    "for q in query.values:\n",
    "    buff = []\n",
    "    similarity.append([np.dot(q, d) / (np.linalg.norm(q) * np.linalg.norm(d)) for d in do])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('R17335883.csv', similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transition probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'assg2WebLinks.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((5, 5))\n",
    "\n",
    "with open('./Assignment2_Files/'+file_name) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        row = [int(r) for r in row]\n",
    "        for r in row:\n",
    "            adjacency_matrix[i, r-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_matrix = np.zeros((5, 5))\n",
    "\n",
    "for c in range(len(adjacency_matrix)):\n",
    "    probability_matrix[:, c] = adjacency_matrix[:, c] / np.sum(adjacency_matrix[:, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./Assignment2_Files/T17335883.csv', probability_matrix, fmt='%.4f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as LA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'T17335883.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_matrix = pd.read_csv('./Assignment2_Files/'+file_name, header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val, eig_vec = LA.eig(probability_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized\n",
    "for i in range(len(eig_vec)):\n",
    "    eig_vec[i] = eig_vec[i] / np.linalg.norm(eig_vec[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = np.round(np.real(eig_vec[:, eig_val.argmax()]), decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Assignment2_Files/P17335883.csv', 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        writer.writerow(pagerank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
